Sobre el desafÃ­o
Challenge Telecom X - Part 2 es parte del programa de desafÃ­os de Alura + Oracle enfocado en Data Science y Machine Learning . Este proyecto desarrolla un modelo predictivo para identificar clientes con alta probabilidad de cancelar servicios de telecomunicaciones (churn), aplicando tÃ©cnicas avanzadas de ciencia de datos.
ğŸ† Objetivos del desafÃ­o:

Desarrollar un modelo de Machine Learning para predecir el abandono
Aplicar tÃ©cnicas de preprocesamiento e ingenierÃ­a de caracterÃ­sticas.
Implementar mejores practicas de ciencia de datos
Generar insights accionables para el negocio
Crear un pipeline completo listo para producciÃ³n

ğŸ“Š Resultados Alcanzados
ğŸ¯ MÃ©tricas del Modelo:

ğŸ† AUC-ROC: 0.8314 (Excelente capacidad discriminativa)
ğŸ“ˆ PrecisiÃ³n Global: 76%
ğŸ¯ Recall para Churn: 74%
âš¡ 15 caracterÃ­sticas claves identificadas
ğŸš€ Modelo optimizado con aumento de gradiente

ğŸ“‹ Conjunto de datos procesado:

ğŸ“Š 7,267 clientes analizados
ğŸ”¢ 21 variables originales
ğŸ“ˆ 25.72% tasa de abandono (desequilibrado)
âš–ï¸ Balanceamiento aplicado con SMOTE

Hallazgos Principales
ğŸ¯ Top 5 Factores CrÃ­ticos de Churn:
RangoVariableImportanciaPerspectiva de negocio1ï¸âƒ£DuraciÃ³n del cliente20%Clientes nuevos tienen mayor riesgo2ï¸âƒ£Contratos de 2 aÃ±os19%Factor de retenciÃ³n mÃ¡s fuerte3ï¸âƒ£Contratos de 1 aÃ±o15%RetenciÃ³n moderada versus mensual4ï¸âƒ£Pago electrÃ³nico11%MÃ©todo menos estable5ï¸âƒ£Cargos mensuales10%Sensibilidad al precio
ğŸ’¡ Insights Clave para el Negocio:

ğŸ•’ AntigÃ¼edad : Primeros 12 meses son crÃ­ticos
ğŸ“‹ Contratos : Largo plazo reduce significativamente la deserciÃ³n
ğŸ’³ Pagos : DÃ©bito automÃ¡tico es mÃ¡s estable que cheque electrÃ³nico
ğŸŒ Fibra Ã“ptica : Clientes premium mÃ¡s propensos al abandono

ğŸ› ï¸ MetodologÃ­a Aplicada
1. ğŸ“Š AnÃ¡lisis Exploratorio
pitÃ³n# AnÃ¡lisis de distribuciÃ³n de churn
churn_distribution = df['Churn'].value_counts(normalize=True)
print(f"No Churn: {churn_distribution[0]:.1%}")
print(f"Churn: {churn_distribution[1]:.1%}")
2. ğŸ”„ CanalizaciÃ³n de preprocesamiento
pitÃ³n# Pipeline de preprocesamiento
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_features),
    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)
])
3. âš–ï¸ Equilibrio de Clases
pitÃ³n# AplicaciÃ³n de SMOTE
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_preprocessed, y_train)
4. ğŸ¯ SelecciÃ³n de caracterÃ­sticas
pitÃ³n# SelecciÃ³n de mejores caracterÃ­sticas
selector = SelectKBest(score_func=f_classif, k=15)
X_train_selected = selector.fit_transform(X_train_res, y_train_res)
5. ğŸ¤– Modelado y OptimizaciÃ³n
pitÃ³n# Modelos comparados
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42)
}

# OptimizaciÃ³n con GridSearchCV
gb_params = {
    'n_estimators': [100, 200],
    'learning_rate': [0.05, 0.1], 
    'max_depth': [3, 5]
}
ğŸ“ˆ ComparaciÃ³n de modelos
ModeloAUC-ROCPrecisiÃ³n GlobalRecuperaciÃ³n de abandonoPuntuaciÃ³n F1TiempoğŸ¥‡ PotenciaciÃ³n de gradientes0.831476%74%0.62MedioğŸ¥ˆ RegresiÃ³n logÃ­stica0.832674%80%0.62RÃ¡pidoğŸ¥‰ Bosque aleatorio0.802476%58%0,55Lento
ğŸ† Mejor modelo: aumento de gradiente optimizado

ParÃ¡metros Ã³ptimos :learning_rate=0.1, max_depth=5, n_estimators=200
Balanza ideal : Entre precisiÃ³n y recuperaciÃ³n
Interpretabilidad : Clara identificaciÃ³n de factores importantes

ğŸ—‚ï¸ Estructura del Proyecto
Challenge-Telecom-X-Part2/
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â”œâ”€â”€ 01_Exploratory_Data_Analysis.ipynb     # EDA completo
â”‚   â”œâ”€â”€ 02_Data_Preprocessing.ipynb            # Limpieza y transformaciÃ³n
â”‚   â”œâ”€â”€ 03_Feature_Engineering.ipynb           # CreaciÃ³n de caracterÃ­sticas
â”‚   â”œâ”€â”€ 04_Model_Training_Evaluation.ipynb     # Entrenamiento y evaluaciÃ³n
â”‚   â””â”€â”€ 05_Business_Insights_Conclusions.ipynb # Conclusiones de negocio
â”‚
â”œâ”€â”€ ğŸ“Š data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales del challenge
â”‚   â”œâ”€â”€ processed/              # Datos procesados
â”‚   â””â”€â”€ results/               # Resultados y predicciones
â”‚
â”œâ”€â”€ ğŸ¤– models/
â”‚   â”œâ”€â”€ telecom_churn_model.pkl              # Modelo final optimizado
â”‚   â”œâ”€â”€ preprocessor.pkl                     # Pipeline de preprocesamiento
â”‚   â””â”€â”€ feature_selector.pkl                 # Selector de caracterÃ­sticas
â”‚
â”œâ”€â”€ ğŸ“ˆ reports/
â”‚   â”œâ”€â”€ figures/               # Visualizaciones generadas
â”‚   â”œâ”€â”€ challenge_report.pdf   # Reporte final del challenge
â”‚   â””â”€â”€ presentation.pptx      # PresentaciÃ³n de resultados
â”‚
â”œâ”€â”€ ğŸ src/
â”‚   â”œâ”€â”€ data_processing.py     # Funciones de procesamiento
â”‚   â”œâ”€â”€ model_training.py      # Entrenamiento de modelos
â”‚   â”œâ”€â”€ evaluation_metrics.py  # MÃ©tricas de evaluaciÃ³n
â”‚   â””â”€â”€ visualization.py       # Funciones de visualizaciÃ³n
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt         # Dependencias del proyecto
â”œâ”€â”€ ğŸš€ main.py                 # Script principal de ejecuciÃ³n
â”œâ”€â”€ ğŸ“– README.md               # Este archivo
â””â”€â”€ ğŸ“„ LICENSE                 # Licencia MIT
ğŸš€ Reproducir el desafÃ­o
OpciÃ³n 1: Google Colab (Recomendado) ğŸŒŸ
intento# 1. Abrir en Google Colab
https://colab.research.google.com/

# 2. Cargar notebook principal
# 3. Subir dataset del challenge
# 4. Ejecutar todas las celdas secuencialmente
OpciÃ³n 2: Entorno Local ğŸ’»
intento# 1. Clonar repositorio
git clone https://github.com/tu-usuario/Challenge-Telecom-X-Part2.git
cd Challenge-Telecom-X-Part2

# 2. Crear entorno virtual
python -m venv telecom-env
source telecom-env/bin/activate  # Linux/Mac
# telecom-env\Scripts\activate   # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Ejecutar anÃ¡lisis completo
python main.py
OpciÃ³n 3: EjecuciÃ³n RÃ¡pida âš¡
pitÃ³n# Cargar modelo pre-entrenado
import joblib
model = joblib.load('models/telecom_churn_model.pkl')

# Predecir churn para nuevos clientes
predictions = model.predict(new_customer_data)
probabilities = model.predict_proba(new_customer_data)[:, 1]
ğŸ“‹ Dependencias del Proyecto
TXT# Core Data Science
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0

# Preprocessing & Balancing
imbalanced-learn>=0.8.0

# Visualization
matplotlib>=3.4.0
seaborn>=0.11.0
plotly>=5.0.0

# Model Persistence
joblib>=1.1.0

# Jupyter Environment
jupyter>=1.0.0
ipykernel>=6.0.0

# Utilities
tqdm>=4.62.0
ğŸ’¼ Valor de Negocio - Reto Telecom X
ğŸ¯ Impacto Proyectado:

ğŸ“ˆ 15-20% de incremento en retenciÃ³n de clientes
ğŸ’° ReducciÃ³n de 15-25% en tasa de abandono
ğŸ¯ ROI positivo en programas de retenciÃ³n dirigidos
âš¡ IdentificaciÃ³n temprana de clientes en riesgo

ğŸ“Š KPIs mejorados:
MÃ©tricaAntesDespuÃ©sMejoraRetenciÃ³n74,3%85-90%+15%DetecciÃ³n ChurnManual74% Auto+74%Tiempo RespuestaDÃ­asTiempo Real-99%PrecisiÃ³n Acciones20%76%+280%
ğŸ† Logros del DesafÃ­o
âœ… Objetivos cumplidos:

 Modelo predictivo con AUC > 0,80
 Pipeline automatizado completo
 IngenierÃ­a de funciones optimizada
 Insights de negocio accionables
 DocumentaciÃ³n completa del proceso.
 CÃ³digo reproducible y escalable

ğŸŒŸTÃ©cnicas Aplicadas:

Preprocesamiento avanzado con ColumnTransformer
Equilibrio inteligente con SMOTE
SelecciÃ³n automÃ¡tica de caracterÃ­sticas
OptimizaciÃ³n de hiperparÃ¡metros con GridSearchCV
ValidaciÃ³n cruzada estratificada
EvaluaciÃ³n multimÃ©trica integral

ğŸ‘¨â€ğŸ’» Autor
Jim Rodriguez - CientÃ­fico de Datos en formaciÃ³n

ğŸ“§ Correo electrÃ³nico : jarodriguezserna@gmail.com
ğŸ’¼ LinkedIn : https://www.linkedin.com/in/jim-rodr%C3%ADguez-508166361/
ğŸ™ GitHub : https://github.com/JimRodriguez99


ğŸ† Â¡ Reto Completado con Ã‰xito!
